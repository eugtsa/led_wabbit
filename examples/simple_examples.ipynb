{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of vw wrapper usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Attention!</font> If work with wrapper is done within jupyter-notebook then parameter <font color='red'> log_stderr_to_file=True </font> should be passed on classifier instance creation. Later, after work is done, temporary directories with cache, temporary models and stdin/stdout should be <font color='red'> deleted </font> (check out this notebook's last cells).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header dictionary overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One necessary parameter \"header_dict\" should be passed to classifier(or regressor) constructor when instance is created. This parameter contains dictionary with input features data mapping.\n",
    "\n",
    "Header dictionary example:\n",
    "<pre>\n",
    "header_dict = {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}\n",
    "</pre>\n",
    "\n",
    "\n",
    "Header dictionary format:\n",
    "- keys are indexes of columns in input numpy array X (which would be passed to fit method). <font color='red'> Attention! </font> amount of keys should be same as number of columns in input feature-array X. Also they should be in range 0 - t-1 if there are t columns in input data X.  \n",
    "- values of dictionary are triples:\n",
    "    - feature type - 'n' for numerical feature, 'с' for categorical.\n",
    "    - feature namespace. \n",
    "    - feature name. If feture type is numerical in header_dict, this name would be used for generating vw line (for example, ('n', 'Y', 'y0') would be converted to : ... |Y y0:{float_val} ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры работы с обертками для vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Внимание!</font> При работе из jupyter-notebook необходимо передавать параметр<font color='red'> log_stderr_to_file=True </font> при создании инстанса классификатора. Затем, при окончании работы, <font color='red'> удалить </font> временные папки с кешами, stdout и stderr vw (см. конец данного ноутбука)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обязательным параметром является header_dict - это словарь, содержащий описание входных данных (которые будут переданы в numpy-массиве X). \n",
    "\n",
    "Пример словаря:\n",
    "<pre>\n",
    "header_dict = {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}\n",
    "</pre>\n",
    "\n",
    "\n",
    "Формат словаря-заголовка:\n",
    "- ключами являются номера полей во входном numpy-массиве (который будет передан в fit). <font color='red'> Внимание! </font> количество ключей должно совпадать с количеством столбцов в массиве, при этом нумерацию необходимо начинать с нуля.  \n",
    "- значениями являются тройки, состоящи из:\n",
    "    - тип фичи. 'n' - если фича является числовой, 'с' - если фича является категориальной\n",
    "    - домен фичи. \n",
    "    - название фичи. Если выбран числовой тип фичи, то это название будет внутри домена при подаче строк в vw. (Например, при ('n', 'Y', 'y0') в vw будет подана строчка : ... |Y y0:{float_val} ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary logistic regression\n",
    "## Логистическая бинарная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsa/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "{'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.5, 'log_stderr_to_file': True, 'passes': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsa/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "from led_wabbit.models import LogisticRegressionBinary\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X1 = [[0, 1, 1] for i in range(40)]\n",
    "    X2 = [[0, 2, 0] for i in range(40)]\n",
    "    X3 = [[1, 0, 1] for i in range(40)]\n",
    "    X4 = [[0, 2, 2] for i in range(3)]\n",
    "\n",
    "    X = np.array([x for x in chain(X1, X2, X3, X4)])\n",
    "\n",
    "    Y1 = [0 for i in range(40)]\n",
    "    Y2 = [1 for i in range(40)]\n",
    "    Y3 = [0 for i in range(40)]\n",
    "    Y4 = [1 for i in range(3)]\n",
    "\n",
    "    Y = np.array([y for y in chain(Y1, Y2, Y3, Y4)])\n",
    "\n",
    "    X, Y = shuffle(X, Y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "    header_dict = {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}\n",
    "\n",
    "    clf = LogisticRegressionBinary(passes=5, header_dict=header_dict)# loss='logistic',\n",
    "\n",
    "    params = {'passes':[50, 100], 'header_dict':[header_dict],\\\n",
    "              'learning_rate':[0.5, 0.2, 0.8],'log_stderr_to_file':[True]} # 'loss':['logistic'],\n",
    "    gs = GridSearchCV(clf, params, scoring='roc_auc', n_jobs=4)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.04922907, 0.06672017, 0.04654511, 0.06028541, 0.0368065 ,\n",
      "       0.05125666]), 'std_fit_time': array([0.00585093, 0.00986627, 0.00288262, 0.00605127, 0.00532435,\n",
      "       0.00267359]), 'mean_score_time': array([0.01877586, 0.01990628, 0.01903725, 0.01651239, 0.01622359,\n",
      "       0.01614849]), 'std_score_time': array([0.00278521, 0.00045301, 0.0017257 , 0.00107927, 0.00118341,\n",
      "       0.00112373]), 'param_header_dict': masked_array(data=[{0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')},\n",
      "                   {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')},\n",
      "                   {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')},\n",
      "                   {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')},\n",
      "                   {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')},\n",
      "                   {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.5, 0.5, 0.2, 0.2, 0.8, 0.8],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_log_stderr_to_file': masked_array(data=[True, True, True, True, True, True],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_passes': masked_array(data=[50, 100, 50, 100, 50, 100],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.5, 'log_stderr_to_file': True, 'passes': 50}, {'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.5, 'log_stderr_to_file': True, 'passes': 100}, {'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.2, 'log_stderr_to_file': True, 'passes': 50}, {'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.2, 'log_stderr_to_file': True, 'passes': 100}, {'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.8, 'log_stderr_to_file': True, 'passes': 50}, {'header_dict': {0: ('n', 'X', 'x0'), 1: ('n', 'Y', 'y0'), 2: ('n', 'Z', 'z0')}, 'learning_rate': 0.8, 'log_stderr_to_file': True, 'passes': 100}], 'split0_test_score': array([1.       , 1.       , 0.9672619, 0.9672619, 1.       , 1.       ]), 'split1_test_score': array([1., 1., 1., 1., 1., 1.]), 'split2_test_score': array([0.9264214, 1.       , 0.9264214, 0.9264214, 1.       , 1.       ]), 'mean_test_score': array([0.97591973, 1.        , 0.96461021, 0.96461021, 1.        ,\n",
      "       1.        ]), 'std_test_score': array([0.03452438, 0.        , 0.02982628, 0.02982628, 0.        ,\n",
      "       0.        ]), 'rank_test_score': array([4, 1, 5, 5, 1, 1], dtype=int32), 'split0_train_score': array([1.        , 1.        , 0.96153846, 0.96153846, 1.        ,\n",
      "       1.        ]), 'split1_train_score': array([1., 1., 1., 1., 1., 1.]), 'split2_train_score': array([0.98187549, 1.        , 0.98187549, 0.98187549, 1.        ,\n",
      "       1.        ]), 'mean_train_score': array([0.9939585 , 1.        , 0.98113798, 0.98113798, 1.        ,\n",
      "       1.        ]), 'std_train_score': array([0.00854397, 0.        , 0.01571052, 0.01571052, 0.        ,\n",
      "       0.        ])}\n"
     ]
    }
   ],
   "source": [
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsa/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/tsa/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4044.4338287944806\n",
      "{'header_dict': {0: ('n', 'X', 'x0')}, 'learning_rate': 1.0, 'log_stderr_to_file': True, 'passes': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from led_wabbit.models import LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "    # Split the data into training/testing sets\n",
    "    diabetes_X_train = diabetes_X[:-20]\n",
    "    diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "    # Split the targets into training/testing sets\n",
    "    diabetes_y_train = diabetes.target[:-20]\n",
    "    diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "    header_dict = {0: ('n', 'X', 'x0')}\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression(passes=15, header_dict=header_dict)\n",
    "\n",
    "    params = {'passes': [1, 2, 3, 10, 30, 50, 100, 200, 500], 'header_dict': [header_dict], \\\n",
    "              'learning_rate': [0.2, 0.5, 0.8, 1.0],'log_stderr_to_file':[True]}  # 'loss':['logistic'],\n",
    "\n",
    "    gs = GridSearchCV(regr, params, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "\n",
    "    gs.fit(diabetes_X_train, diabetes_y_train)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After completion of work, temporary files containing temporary models, their caches, stdout and stderr files should be deleted\n",
    "## После окончания всех работ или грид-серча почистим файлы с моделями, кешами, логами ошибок и stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This should be done only if you use wrapper with jupyter or ipython notebook\n",
    "\n",
    "### Чистку необходимо делать только если работа производится из jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf temp-vw*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
